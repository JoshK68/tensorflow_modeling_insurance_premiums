{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "mount_file_id": "14kos1dIBgJBabxixk3axKTW-Sg_1sDJE",
      "authorship_tag": "ABX9TyNtODtpTswcVpfUvUKQxjWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshKonoff/tensorflow_modeling_insurance_premiums/blob/main/simple_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7qCAVj_GJ_P"
      },
      "source": [
        "#Regression with Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_d2eA0rRFkD"
      },
      "source": [
        "#Predicting a number based on some other numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEGOGEXvUNa5",
        "outputId": "cd259c45-cd9e-4bce-c290-8a68fa2e9fb0"
      },
      "source": [
        "#Import TF\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "J5IS7HihUeuN",
        "outputId": "a70051d6-1953-483b-f171-e1ec433e93fa"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])   #X is our independent variables\n",
        "\n",
        "#Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])   #y is our dependent variable\n",
        "\n",
        "#Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESCN1XxLVZPK"
      },
      "source": [
        "#Think about  it: What's the relationship btwn X and y?\n",
        "#How can we use X to get y?\n",
        "# y = x+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qx5JvDEVZsr",
        "outputId": "691e3229-8bb0-46ad-db41-16b4a064c427"
      },
      "source": [
        "#X+10\n",
        "y == X + 10   #this is the relationship for our neural network to learn. This is the relationship btwn X and y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpiVUOdVWBJT"
      },
      "source": [
        "#What are our input and output shapes\n",
        "#In the houses example the input shape was 3 (number of bedrooms, # of bathrooms, # of garages) and the output shape was 1 (the predicted price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Zy9k2cWaE4",
        "outputId": "ed3f6575-eab1-4e0f-91eb-8f0e95431b2b"
      },
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant(['bed', 'bathrooms', 'garage'])\n",
        "house_price = tf.constant([939700])\n",
        "\n",
        "house_info, house_price"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bed', b'bathrooms', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLjEOciXXgaj",
        "outputId": "d8cdb893-70a3-4976-9ab4-28fd9f89d917"
      },
      "source": [
        "#How can we use X to predict y?\n",
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-qQ8rw4X4Qx",
        "outputId": "d011bdbd-be39-4d13-ea44-8f602ad64b62"
      },
      "source": [
        "#We want to use X[0] to predict y[0]\n",
        "X[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiYS8U3oYSPQ",
        "outputId": "064b5889-8027-4ce5-b85a-6e4bda4077d9"
      },
      "source": [
        "X[1], y[1]   #Keep in mind that we're going to use one X value to predict one y value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d517gdFnZJZe",
        "outputId": "098d6922-0d6a-45f3-aed5-2595fb7c3958"
      },
      "source": [
        "# Let's turn our Numpy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RT01C8HZW9y",
        "outputId": "4ea6bc73-55ca-4589-b854-550b924fb7b7"
      },
      "source": [
        "input_shape = X[0].shape   #let's check the shape now that they're in tensor form\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "bPd3TQvYZy_3",
        "outputId": "30567302-d27b-4756-c6a6-162029d3e3e8"
      },
      "source": [
        "#How might we build a model to predict the relationships here?\n",
        "plt.scatter(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f9302f90950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNnWwlBPZ-T0"
      },
      "source": [
        "#Steps in modelling with TF\n",
        "\n",
        "# Creating a model - define the input and output layers, as well as the hidden layers of a deep learning model\n",
        "# Compiling a model - define the loss function (in other words the function that tells our model how wrong it is)\n",
        "# The optimizer (tells our model how to improve the patterns it's learning) and evaluation metricts (what we can use to interpret the performance of our model).\n",
        "# Fitting a model - letting the model try to find patterns between X and y (features and labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IecelM7Sbh1Y",
        "outputId": "7d1c42a3-360f-45f5-aa9e-72be81a0a157"
      },
      "source": [
        "# Set random seed\n",
        "\n",
        "tf.random.set_seed(42)   #Set the seed so that we have reproducibility  (?)\n",
        "\n",
        "# Create a model using the Seuqnetial API\n",
        "\n",
        "#This is telling tensorflow 'I want to create a model and I want you to sequentially go through the following \n",
        "model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(1)      #We put one here b/c we put in 1 number and to predict one number\n",
        "])      \n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,   #mae = mean absolute error = calculated 'on average how wrong are our predictions'\n",
        "             optimizer = tf.keras.optimizers.SGD(), #sgd is short for stochastic gradient descent - stochastic means random - an optimizer tells our neural network how it should improve\n",
        "             metrics= ['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 557ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92feab7650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AygITR1edt96",
        "outputId": "1b61eca8-e851-42f1-b88f-568e993ccea1"
      },
      "source": [
        "#Check out X and y\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULOJFBcdxUV8",
        "outputId": "cf152b47-9986-4a57-b320-c7caf2773a24"
      },
      "source": [
        "# Try to make a prediction using our model\n",
        "model.predict([17.0])   #Our model predicts that if we have an X value of 17, our y value would be 12.7\n",
        "#That's pretty far off, but as we can see in line 15 above, that actually makes sense b/c our model's predictions are about 11 points off"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ6MT-9yyL_I",
        "outputId": "015e129c-4159-4667-db3e-8c6443740f4e"
      },
      "source": [
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdKk_lqhy0K7"
      },
      "source": [
        "Improve our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-GeKEYqy3ki"
      },
      "source": [
        "#We can improve our model, by altering the steps we took to create a model\n",
        "\n",
        "#What might we be able to do to improve our model?\n",
        "# 1. Creating a model - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, or change the activation function of each layer\n",
        "# 2. Compile - here we might change the optimization functions or perhaps the learning rate of said optimization functions\n",
        "# 3. Fitting a model - here we might fit a model for more 'epochs' (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLzT06v21KcY",
        "outputId": "8b7e84fe-8e2e-4bbb-c1bc-014da43f623e"
      },
      "source": [
        "#Let's rebuild our model\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=['mae'])\n",
        "\n",
        "#3. Fit the model (this time we'll train for longer)\n",
        "model.fit(X, y, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 258ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8869 - mae: 6.8869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fc893fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDI9xF3k2acl",
        "outputId": "7b95ca6d-384e-4d4f-de4c-f024eb09a32c"
      },
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZM2hfK-2gPO"
      },
      "source": [
        "#We tried to make a prediction - what value should follow the 14 at the end (it should be 17 based on the other values of X and y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t89G-1h2uu9",
        "outputId": "44ace818-2ed7-4306-eac8-c9beae06d901"
      },
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.0])    #if we put 17 in the first array, we should get 27 in the bottom one\n",
        "\n",
        "####It is much closer now. - by tweaking on single parameter\n",
        "#It was 12.7\n",
        "#Now it's 29.9\n",
        "\n",
        "#In both cases it was supposed to be 27\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M_jwTbb337g",
        "outputId": "e3483bc9-fd65-408d-d978-6c18258414ae"
      },
      "source": [
        "#Let's rebuild our model again\n",
        "\n",
        "#Create a model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(50, activation=None),\n",
        "        tf.keras.layers.Dense(1)                     \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),   #Keep in mind that your learning rate (lr) is potentially the most important hyperparameter that you can change\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X, y, epochs = 100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 11.7682 - mae: 11.7682\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0963 - mae: 11.0963\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4150 - mae: 10.4150\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7212 - mae: 9.7212\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0104 - mae: 9.0104\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2778 - mae: 8.2778\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.5198 - mae: 7.5198\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9648 - mae: 6.9648\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0672 - mae: 7.0672\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.3315 - mae: 7.3315\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.4673 - mae: 7.4673\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.5285 - mae: 7.5285\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4011 - mae: 7.4011\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.1923 - mae: 7.1923\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9575 - mae: 6.9575\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6953 - mae: 6.6953\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4127 - mae: 6.4127\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3048 - mae: 6.3048\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2575 - mae: 6.2575\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3982 - mae: 6.3982\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4551 - mae: 6.4551\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4000 - mae: 6.4000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.2482 - mae: 6.2482\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0105 - mae: 6.0105\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7876 - mae: 5.7876\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6809 - mae: 5.6809\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5715 - mae: 5.5715\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6122 - mae: 5.6122\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6074 - mae: 5.6074\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5541 - mae: 5.5541\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4568 - mae: 5.4568\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3199 - mae: 5.3199\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1477 - mae: 5.1477\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9442 - mae: 4.9442\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.8239 - mae: 4.8239\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7389 - mae: 4.7389\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6657 - mae: 4.6657\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5846 - mae: 4.5846\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4027 - mae: 4.4027\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2653 - mae: 4.2653\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1212 - mae: 4.1212\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9702 - mae: 3.9702\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8272 - mae: 3.8272\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7041 - mae: 3.7041\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.5320 - mae: 3.5320\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3664 - mae: 3.3664\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2116 - mae: 3.2116\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0463 - mae: 3.0463\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8705 - mae: 2.8705\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6840 - mae: 2.6840\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4868 - mae: 2.4868\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2787 - mae: 2.2787\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0596 - mae: 2.0596\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8293 - mae: 1.8293\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5876 - mae: 1.5876\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3530 - mae: 1.3530\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0849 - mae: 1.0849\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8224 - mae: 0.8224\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5467 - mae: 0.5467\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2758 - mae: 0.2758\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1354 - mae: 0.1354\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4494 - mae: 0.4494\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6498 - mae: 0.6498\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6216 - mae: 0.6216\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8036 - mae: 0.8036\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7995 - mae: 0.7995\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7409 - mae: 0.7409\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7806 - mae: 0.7806\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6305 - mae: 0.6305\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5556 - mae: 0.5556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4306 - mae: 0.4306\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2786 - mae: 0.2786\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1378 - mae: 0.1378\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1193 - mae: 0.1193\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2777 - mae: 0.2777\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3245 - mae: 0.3245\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4157 - mae: 0.4157\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4319 - mae: 0.4319\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3391 - mae: 0.3391\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2968 - mae: 0.2968\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2355 - mae: 0.2355\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1633 - mae: 0.1633\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1339 - mae: 0.1339\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1262 - mae: 0.1262\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1702 - mae: 0.1702\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2124 - mae: 0.2124\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2288 - mae: 0.2288\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1901 - mae: 0.1901\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1354 - mae: 0.1354\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1218 - mae: 0.1218\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0382 - mae: 0.0382\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2197 - mae: 0.2197\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2189 - mae: 0.2189\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.1427\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1168 - mae: 0.1168\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.2069 - mae: 0.2069\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1524 - mae: 0.1524\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2133 - mae: 0.2133\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2329 - mae: 0.2329\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0780 - mae: 0.0780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fb725390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp-JBd8A5vS1",
        "outputId": "a40494f9-2501-410a-c85b-29f9a7fdeb66"
      },
      "source": [
        "X, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVzn1dFb5wxX",
        "outputId": "8edb2484-6e2e-4ffb-a5d8-8c2264f569fe"
      },
      "source": [
        "model.predict([17.0]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.58353]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkF3H_vX-FQH"
      },
      "source": [
        "### Evaluation a model\n",
        "\n",
        "\n",
        "#In practice, a typical workflow you'll go through when building a neural network is:\n",
        "#Built a model -> fit it -> evaluate it -> tweak it --> fit it --> evaluate it --> tweak it --> fit it -> evaluate it...'''\n",
        "\n",
        "#The tyings that you can alter, such as tf.keras.layers.Dense() and 'Adam' are called hyperparameters b/c you can adjust them\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewiQwgu1vCKX",
        "outputId": "cea2550a-902b-4dd0-92e6-0bfd17ba9c7e"
      },
      "source": [
        "#Make a bigger dataset\n",
        "X = tf. range(-100, 100, 4)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmJIU_yTvYy7",
        "outputId": "bec79171-48ce-47ff-a941-78465af19360"
      },
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ulvuPSvBvoYt",
        "outputId": "4c71113f-8337-4ab7-d3b9-15427a04addc"
      },
      "source": [
        "#So it's a good idea to visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f92fa0e7690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBNbBNO9v_-e"
      },
      "source": [
        "#Split X and y into an 80 training and 20% test set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-MtSeFTwRKi"
      },
      "source": [
        "###Usually you'll have three sets\n",
        "\n",
        "#Training set - maybe 70-80% of the total data you have available.\n",
        "#Validation set - the model gets tuned on this data, which is typically 10-15% of the data available.  (this set is sometimes valuable)\n",
        "#Test set - the model gets evaluated on this data to test what it has learned, this set is typically 10-15% of the total data avail\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbwEoG-Mw5LX"
      },
      "source": [
        "#Example of three datasets\n",
        "\n",
        "#If you're studying at university\n",
        "\n",
        "#1. Course materials - training set\n",
        "#2. Practice exam - validation set\n",
        "#3. Final exam - test set\n",
        "\n",
        "#Generalization - the ability for a machine learning model to perform well on data that it hasn't seen before"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwGlProPxvCD",
        "outputId": "bf72699c-cfb0-4a7c-fffa-c50d2cf87b6d"
      },
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL1cyEdOx-E7",
        "outputId": "679f5514-7b98-44fd-b410-14d1e509fcc2"
      },
      "source": [
        "# Split the data into train and test sets  (well skip validation b/c 50 is a small set)\n",
        "X_train = X[:40] # First 40 are training samples(80% of the data )\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] #the last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7I2HRh4zS3u"
      },
      "source": [
        "It's a good idea to visualize our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "p1IZ_X5HzWMs",
        "outputId": "d7ccccb1-c9a9-44f2-a722-84c13fb11f40"
      },
      "source": [
        "#Now we've got our data in training and test sets...let's visualize it again!\n",
        "plt.figure(figsize=(10,7))\n",
        "#Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c='b', label='Training data')  #c='b' for blue. Our model will learn on this\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c='g', label='Testing data') #We want our model to be able to predict this\n",
        "#Show a legend\n",
        "plt.legend()  #shows the legend in the upper left so that we don't get our training and test data confused"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f92f98d1dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_EOCxAj0y9v"
      },
      "source": [
        "#Right now we have a training set which is the blue\n",
        "#and a testing set which is the green"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtJuumU106d4"
      },
      "source": [
        "#What we want to do next is build a neural network to learn the relationship between X and y\n",
        "#We then want our model to predict the test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvzuK_xg1xlM",
        "outputId": "465aac68-4b1e-443a-e8cb-d3d8761811f5"
      },
      "source": [
        "#Let's look at how to create a neural network for our data\n",
        "\n",
        "#1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "                        tf.keras.layers.Dense(1, input_shape=[1])       \n",
        "                             ])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.SGD(),   #Keep in mind that your learning rate (lr) is potentially the most important hyperparameter that you can change\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(X_train, y_train, epochs = 100)   #we want to fit on the training data only (the blue line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5273 - mae: 10.5273\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.3906 - mae: 9.3906\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6292 - mae: 7.6292\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6859 - mae: 9.6859\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0740 - mae: 11.0740\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.2264 - mae: 10.2264\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2347 - mae: 9.2347\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1547 - mae: 9.1547\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7875 - mae: 11.7875\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.7172 - mae: 13.7172\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8015 - mae: 11.8015\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3555 - mae: 16.3555\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.9043 - mae: 11.9043\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.8239 - mae: 13.8239\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.2084 - mae: 11.2084\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5877 - mae: 8.5877\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 13.7567 - mae: 13.7567\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.6177 - mae: 11.6177\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7100 - mae: 17.7100\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8462 - mae: 14.8462\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7513 - mae: 10.7513\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.4917 - mae: 8.4917\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.7766 - mae: 9.7766\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8531 - mae: 10.8531\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1113 - mae: 9.1113\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0840 - mae: 13.0840\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4066 - mae: 10.4066\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.4238 - mae: 13.4238\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6076 - mae: 9.6076\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.2601 - mae: 17.2601\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.8003 - mae: 22.8003\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9049 - mae: 7.9049\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.1734 - mae: 14.1734\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4283 - mae: 12.4283\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2339 - mae: 8.2339\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4408 - mae: 10.4408\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0926 - mae: 10.0926\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.2658 - mae: 11.2658\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.7947 - mae: 14.7947\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.9246 - mae: 12.9246\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3199 - mae: 9.3199\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9560 - mae: 10.9560\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3161 - mae: 8.3161\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.9795 - mae: 12.9795\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.7222 - mae: 13.7222\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4129 - mae: 8.4129\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1536 - mae: 9.1536\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6543 - mae: 10.6543\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.7674 - mae: 7.7674\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5726 - mae: 9.5726\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1575 - mae: 9.1575\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4515 - mae: 16.4515\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.0818 - mae: 14.0818\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 21.0172 - mae: 21.0172\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4738 - mae: 16.4738\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8662 - mae: 9.8662\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6413 - mae: 9.6413\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9628 - mae: 8.9628\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1686 - mae: 10.1686\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4129 - mae: 8.4129\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2533 - mae: 9.2533\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0626 - mae: 7.0626\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.6398 - mae: 8.6398\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2166 - mae: 9.2166\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4767 - mae: 10.4767\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.6303 - mae: 15.6303\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0248 - mae: 10.0248\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.0030 - mae: 9.0030\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4993 - mae: 12.4993\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9709 - mae: 8.9709\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9493 - mae: 9.9493\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9817 - mae: 9.9817\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.4756 - mae: 12.4756\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5140 - mae: 10.5140\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.6442 - mae: 9.6442\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1190 - mae: 11.1190\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.2914 - mae: 8.2914\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9997 - mae: 8.9997\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.7057 - mae: 19.7057\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.8733 - mae: 17.8733\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0400 - mae: 7.0400\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4264 - mae: 10.4264\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.8572 - mae: 9.8572\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9069 - mae: 7.9069\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4048 - mae: 9.4048\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.2307 - mae: 9.2307\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0129 - mae: 12.0129\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6296 - mae: 10.6296\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2506 - mae: 7.2506\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7702 - mae: 12.7702\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4544 - mae: 7.4544\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7385 - mae: 6.7385\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.9206 - mae: 11.9206\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.8548 - mae: 8.8548\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6966 - mae: 7.6966\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7327 - mae: 6.7327\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.6033 - mae: 8.6033\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3858 - mae: 9.3858\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1203 - mae: 9.1203\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.4808 - mae: 10.4808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92f97f4e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8CY2WAF12I3",
        "outputId": "94e4cf04-55e0-489e-ab09-13f996665d3f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1fbVl04Y2s"
      },
      "source": [
        "#Total parameters is how many patterns our model is going to try to learn\n",
        "#Trainable parameters - there are the parameters (patterns)\n",
        "#Non-trainable params - these parameters aren't updated during training(this is typical when you bring in already learned patterns or parameters from other models during transfer learning )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54h5vMp05pgK"
      },
      "source": [
        "#Resource: For more in-depth overview check out MIT introduction to deep learning video: https://www.youtube.com/watch?v=5tvmMX8r_OM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDzRw274ZZ2D"
      },
      "source": [
        "#Visualizing our model's predictions\n",
        "\n",
        "To visualize predictions, it's a good idea to plot them again the ground truth labels\n",
        "\n",
        "Often you'll see this in the form of y_test or y_true vs y_pred (ground truth vs your model)'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ-Oz9r6ZuxM",
        "outputId": "bd9a2e11-9aa9-47ec-b42a-63d91c22dee6"
      },
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[56.60357 ],\n",
              "       [60.289223],\n",
              "       [63.974876],\n",
              "       [67.66053 ],\n",
              "       [71.34618 ],\n",
              "       [75.03184 ],\n",
              "       [78.7175  ],\n",
              "       [82.40315 ],\n",
              "       [86.088806],\n",
              "       [89.77446 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd1dHo6naPBw",
        "outputId": "2893cc7c-2369-402e-f3a8-91e5c6fdeb29"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6r0cBMOaczU"
      },
      "source": [
        "#If you feel like you're going to reuse some kind of functionility in the future, it's a good idea to turn it into a function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep-dWvOOdWne",
        "outputId": "17be17ca-0b37-4f24-fa9e-1e06321b0e4e"
      },
      "source": [
        "# Make predictions\n",
        "y_preds = model.predict(X_test)\n",
        "\n",
        "\n",
        "# View the predictions\n",
        "y_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[56.60357 ],\n",
              "       [60.289223],\n",
              "       [63.974876],\n",
              "       [67.66053 ],\n",
              "       [71.34618 ],\n",
              "       [75.03184 ],\n",
              "       [78.7175  ],\n",
              "       [82.40315 ],\n",
              "       [86.088806],\n",
              "       [89.77446 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Fpv74-aqYy"
      },
      "source": [
        "def plot_predictions(train_data=X_train, \n",
        "                     train_labels=y_train, \n",
        "                     test_data=X_test, \n",
        "                     test_labels=y_test, \n",
        "                     predictions=y_preds):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot the predictions in red (predictions were made on the test data)\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show the legend\n",
        "  plt.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "TsnFC6m7chip",
        "outputId": "54f2803b-558a-4536-a068-194c317c4e0b"
      },
      "source": [
        "\n",
        "plot_predictions(train_data=X_train,\n",
        "                 train_labels=y_train,\n",
        "                 test_data=X_test,\n",
        "                 test_labels=y_test,\n",
        "                 predictions=y_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvPJEK-AJT5a"
      },
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "#Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
        "\n",
        "#Since we're working on a regression, two of the main metrics:\n",
        "#MAE - mean absolute error: 'on average, how wrong is each of my models predictions' - MAE is very easy to understand\n",
        "#MSE - mean square error, 'square the average errors' - very similar to MAE but squared - Use this one when larger errors are more significant then smaller errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIgrXGB2LJ9B",
        "outputId": "d0c3342e-ed87-4355-ba3a-dca659ec4314"
      },
      "source": [
        "# Evaluate the model on the test\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 136ms/step - loss: 14.8110 - mae: 14.8110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.810986518859863, 14.810986518859863]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq3hwtloL1ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74a2f7a-37c3-401c-a78b-71c0166350a7"
      },
      "source": [
        "# Calculate the mean absolute error\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=y_pred)   #(what's the y_true= and y_pred= do?)\n",
        "mae"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([31.39643 , 27.71078 , 24.025124, 20.33947 , 16.923054, 14.180898,\n",
              "       12.113001, 10.71937 , 10.      , 10.      ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19qPLTnQNMpp",
        "outputId": "64dee0bf-6f18-4c5c-c87b-ee8dbd7c9b1c"
      },
      "source": [
        "tf.squeeze(y_pred)  #this gets rid of the second number in the shape so that they are the same shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([56.60357 , 60.289223, 63.974876, 67.66053 , 71.34618 , 75.03184 ,\n",
              "       78.7175  , 82.40315 , 86.088806, 89.77446 ], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLnNllpPNZqn",
        "outputId": "ca4c36f1-e6a4-4b02-904c-700cdfd8e139"
      },
      "source": [
        "#Now calculate the mean absolute error\n",
        "\n",
        "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
        "                                     y_pred=tf.squeeze(y_pred))  #squeeze our predictions so that they are the same shape\n",
        "mae #We get the same result as our evaluate function a few lines above"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=14.8109865>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs0jzK-IOK8v",
        "outputId": "b7934764-d80a-43cd-a555-6eaadbd56ea3"
      },
      "source": [
        "#Next calculate the mean square error(MSE)\n",
        "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                   y_pred=tf.squeeze(y_pred))   #How do we know to when to use tf.squeeze?\n",
        "\n",
        "mse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=220.18051>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aehzpG1PncH"
      },
      "source": [
        "# functionize mae and mse to make it easy to reuse later\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
        "                                        y_pred=tf.squeeze(y_pred)\n",
        "                                        )\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true=y_test,\n",
        "                                       y_pred=tf.squeeze(y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHybuVzcQk1D"
      },
      "source": [
        "### Running experiments to improve our model\n",
        "\n",
        "#What are the top three ways to improve our model?\n",
        "#1. Get more data - get more examples for your model to train on(more opportunities to learn patterns or relationships between features and labels).\n",
        "#2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer\n",
        "#3. Train for longer - give your model more of a chance to find patterns in the data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_uSNbw_RQxX",
        "outputId": "6170e472-19ee-408b-a6e4-56771c8db2fe"
      },
      "source": [
        "X_train, y_train\n",
        "#let's make our model better by 'making it larger(more complex model) AND training for longer\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56], dtype=int32)>,\n",
              " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQol065Rl2w"
      },
      "source": [
        "#Let's do 3 modelling experiments\n",
        "#1. model_1 - same as the original model, 1 layer, trained for 100 epochs.\n",
        "#2. model_2 - 2 layers, trained for 100 epochs\n",
        "#3. model_3 - 2 layers, trained for 500 epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOavXN3sSGYq",
        "outputId": "98e54d51-1b62-424c-8a64-bc02345cf0c9"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model_1.compile(loss='mae',\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mae']\n",
        "                )\n",
        "\n",
        "#3. Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7067 - mae: 8.7067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92f864b450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "TgGTI3gZEgXK",
        "outputId": "65374ee4-fe82-41cc-adc4-c989b15a5015"
      },
      "source": [
        "#What would a scientist do next?\n",
        "#They would track their results\n",
        "\n",
        "#Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test) #We're going to make predictions on the test data because our model has never seen the test data and we're interest in how our model will perform on data it's never seen before\n",
        "plot_predictions(predictions=y_preds_1)  #y_preds_1 b/c we just created that"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f92fe09ce60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWo3bAX3FwL8"
      },
      "source": [
        "#Our model didn't do so well. Ideally the green and red would overlap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmo_w5YFG4jr",
        "outputId": "babbaa69-ff49-4a92-a134-9ada7534985e"
      },
      "source": [
        "tf.constant(y_preds_1), tf.squeeze(y_preds_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              " array([[53.57109 ],\n",
              "        [57.05633 ],\n",
              "        [60.541573],\n",
              "        [64.02681 ],\n",
              "        [67.512054],\n",
              "        [70.99729 ],\n",
              "        [74.48254 ],\n",
              "        [77.96777 ],\n",
              "        [81.45301 ],\n",
              "        [84.938255]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([53.57109 , 57.05633 , 60.541573, 64.02681 , 67.512054, 70.99729 ,\n",
              "        74.48254 , 77.96777 , 81.45301 , 84.938255], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl3Q2lChGAVL",
        "outputId": "0489f4d6-37a5-4122-d6ff-5264540facea"
      },
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, tf.squeeze(y_preds_1)) #We got to squeeze these variables to get them into the same shape\n",
        "mse_1 = mse(y_test, tf.squeeze(y_preds_1))\n",
        "mae_1, mse_1\n",
        "\n",
        "#The line is 18.74 from where they should be\n",
        "#if we square them then the error is even larger (3.53.57)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUcY4eXwH6o5"
      },
      "source": [
        "#Let's change our mae and mse functions to automatically squeeze our functions\n",
        "#We went up to line 56 and added tf.squeeze() to make our functions better"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW12EkLoIgc2",
        "outputId": "07690459-3813-47d8-fd44-03c3695897c9"
      },
      "source": [
        "#Build model 2\n",
        "\n",
        "#2 dense layers, trained for 100 epochs\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(10),\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#Compile the model\n",
        "model_1.compile(loss='mae',\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=['mse']   #evaluate it with mse this time while you're training\n",
        "                )\n",
        "\n",
        "#3. Fit the model\n",
        "model_1.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4494 - mse: 78.2639\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 9.2391 - mse: 117.2352\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.6116 - mse: 124.4441\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 8.7602 - mse: 104.9770\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7251 - mse: 107.3715\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.9002 - mse: 85.4333\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.0002 - mse: 77.7548\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.1138 - mse: 70.7955\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.0986 - mse: 559.1677\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3698 - mse: 105.9799\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5493 - mse: 62.0689\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8866 - mse: 123.7755\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 8.9273 - mse: 95.5554\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 10.9891 - mse: 173.7501\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6094 - mse: 215.8447\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4175 - mse: 60.7653\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.6479 - mse: 80.0147\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.2152 - mse: 152.3637\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3227 - mse: 461.1072\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0241 - mse: 325.8939\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5285 - mse: 149.7398\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0450 - mse: 74.3527\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7253 - mse: 91.7713\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5994 - mse: 78.8101\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1121 - mse: 155.1615\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3869 - mse: 403.6599\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.5856 - mse: 211.3671\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7632 - mse: 242.6678\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.0995 - mse: 106.8595\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4324 - mse: 370.4005\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.7275 - mse: 923.4153\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.6583 - mse: 61.1577\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3521 - mse: 110.3895\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9275 - mse: 89.3741\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0428 - mse: 55.2895\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.9966 - mse: 86.4231\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7731 - mse: 83.4777\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.5648 - mse: 121.7820\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0424 - mse: 310.7673\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7918 - mse: 218.1251\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5635 - mse: 105.5703\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4069 - mse: 150.8616\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.9575 - mse: 157.1762\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4550 - mse: 328.8174\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.1913 - mse: 165.2464\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.3175 - mse: 56.8715\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4750 - mse: 100.5946\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0104 - mse: 79.0903\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8868 - mse: 60.3137\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6688 - mse: 88.7862\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.6195 - mse: 84.0591\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.3668 - mse: 185.6755\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7298 - mse: 187.0546\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4147 - mse: 474.9493\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1775 - mse: 370.4787\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3830 - mse: 146.5208\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7312 - mse: 85.7396\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0396 - mse: 68.6489\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2555 - mse: 106.7013\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.4949 - mse: 80.0595\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3574 - mse: 95.0919\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3038 - mse: 57.7245\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2954 - mse: 55.5856\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0381 - mse: 217.8361\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.1088 - mse: 111.0830\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.5762 - mse: 347.1674\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4988 - mse: 123.3971\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3459 - mse: 74.1593\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3723 - mse: 239.2478\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1456 - mse: 55.0865\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.7084 - mse: 241.6160\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.6625 - mse: 80.1613\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7664 - mse: 166.5833\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.6373 - mse: 213.3801\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3771 - mse: 62.1625\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1117 - mse: 138.1602\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0869 - mse: 150.7447\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7024 - mse: 176.9549\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.6771 - mse: 329.5046\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0129 - mse: 175.7793\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1555 - mse: 130.3522\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.1339 - mse: 73.5019\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.0773 - mse: 73.0803\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.7051 - mse: 63.6787\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1770 - mse: 413.9937\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5961 - mse: 179.6126\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4825 - mse: 178.2509\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.5590 - mse: 127.0423\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0280 - mse: 50.9767\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.9257 - mse: 231.0578\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 2ms/step - loss: 6.8810 - mse: 67.6761\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.1209 - mse: 67.2180\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.5510 - mse: 94.1773\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.8979 - mse: 68.7644\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.3865 - mse: 210.5777\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4120 - mse: 87.8220\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.1666 - mse: 228.5844\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.4770 - mse: 75.7093\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2216 - mse: 83.6959\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.6944 - mse: 132.0850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fdf51f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "xVK3Uy-PKDWi",
        "outputId": "e8355dfc-f97d-4fca-ca20-0b49f62c2c78"
      },
      "source": [
        "y_preds_2 = model_2.predict(X_test) #We're going to make predictions on the test data because our model has never seen the test data and we're interest in how our model will perform on data it's never seen before\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f92fdf62cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFo3ShNrKoJx",
        "outputId": "9d4cf39e-33d3-4103-ccd7-3afb8baf904c"
      },
      "source": [
        "mae_2 = mae(y_test, (y_preds_2)) #We got to squeeze these variables to get them into the same shape\n",
        "mse_2 = mse(y_test, (y_preds_2))  #compare y_test with our predictions from the second model\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=59.02484>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3536.0774>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaVxtygJLDNV",
        "outputId": "eb97b97e-f626-4bbf-e26f-0133730fc8aa"
      },
      "source": [
        "#Build model_3\n",
        "\n",
        "#2 layers, trained for 500 epochs\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_3 = tf.keras.Sequential([\n",
        "                               tf.keras.layers.Dense(10),\n",
        "                               tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics = ['mae'])\n",
        "\n",
        "#3. Fit the model\n",
        "model_3.fit(X_train, y_train, epochs=500)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2277 - mae: 20.2277\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4479 - mae: 11.4479\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4842 - mae: 17.4842\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0217 - mae: 7.0217\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.5789 - mae: 23.5789\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.8932 - mae: 16.8932\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2954 - mae: 9.2954\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.3749 - mae: 25.3749\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.4621 - mae: 13.4621\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5238 - mae: 9.5238\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5987 - mae: 14.5987\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5670 - mae: 9.5670\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8092 - mae: 17.8092\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.1782 - mae: 17.1782\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.1182 - mae: 11.1182\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.3071 - mae: 23.3071\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.6144 - mae: 9.6144\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6899 - mae: 10.6899\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0355 - mae: 8.0355\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.6859 - mae: 29.6859\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0714 - mae: 8.0714\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.3086 - mae: 28.3086\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.9014 - mae: 32.9014\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.6291 - mae: 19.6291\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0095 - mae: 7.0095\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.8056 - mae: 21.8056\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9812 - mae: 7.9812\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.0585 - mae: 21.0585\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0107 - mae: 9.0107\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.0502 - mae: 24.0502\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7537 - mae: 9.7537\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3052 - mae: 18.3052\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.5833 - mae: 7.5833\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.5755 - mae: 18.5755\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5360 - mae: 10.5360\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.2694 - mae: 18.2694\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.1658 - mae: 23.1658\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.1362 - mae: 9.1362\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9181 - mae: 8.9181\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4732 - mae: 16.4732\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4208 - mae: 8.4208\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 36.9540 - mae: 36.9540\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.5820 - mae: 25.5820\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5392 - mae: 9.5392\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 26.6058 - mae: 26.6058\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.7248 - mae: 8.7248\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6172 - mae: 15.6172\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3065 - mae: 18.3065\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.1994 - mae: 8.1994\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4964 - mae: 7.4964\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3374 - mae: 18.3374\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2895 - mae: 10.2895\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 29.6425 - mae: 29.6425\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.5556 - mae: 10.5556\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.4537 - mae: 15.4537\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.0174 - mae: 17.0174\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 32.8218 - mae: 32.8218\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7038 - mae: 10.7038\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.9054 - mae: 8.9054\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.1321 - mae: 22.1321\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7113 - mae: 11.7113\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 21.5734 - mae: 21.5734\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.2485 - mae: 19.2485\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0156 - mae: 11.0156\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6187 - mae: 9.6187\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.5908 - mae: 21.5908\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 26.2851 - mae: 26.2851\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8525 - mae: 9.8525\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.5630 - mae: 22.5630\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.1499 - mae: 10.1499\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.0464 - mae: 18.0464\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.8377 - mae: 28.8377\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.5279 - mae: 16.5279\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.2115 - mae: 11.2115\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.5839 - mae: 27.5839\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.2680 - mae: 8.2680\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 9.2580 - mae: 9.2580\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1440 - mae: 18.1440\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5995 - mae: 10.5995\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8992 - mae: 7.8992\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.4015 - mae: 17.4015\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0089 - mae: 11.0089\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.7027 - mae: 11.7027\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 30.4062 - mae: 30.4062\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.5557 - mae: 7.5557\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.9905 - mae: 15.9905\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5579 - mae: 8.5579\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.7339 - mae: 28.7339\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.1689 - mae: 13.1689\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3101 - mae: 18.3101\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7376 - mae: 13.7376\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 13.7104 - mae: 13.7104\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 28.5842 - mae: 28.5842\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0707 - mae: 7.0707\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0550 - mae: 7.0550\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.0067 - mae: 22.0067\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.8443 - mae: 20.8443\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.4713 - mae: 12.4713\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9099 - mae: 17.9099\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.7494 - mae: 13.7494\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 5.4687 - mae: 5.4687\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7006 - mae: 13.7006\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4142 - mae: 9.4142\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.9796 - mae: 20.9796\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5470 - mae: 9.5470\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7256 - mae: 11.7256\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.3772 - mae: 14.3772\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.8579 - mae: 14.8579\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9706 - mae: 14.9706\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8998 - mae: 17.8998\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8327 - mae: 9.8327\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3352 - mae: 18.3352\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0383 - mae: 15.0383\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5874 - mae: 14.5874\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.3015 - mae: 23.3015\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3613 - mae: 13.3613\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.8517 - mae: 9.8517\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.5451 - mae: 12.5451\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 4.9472 - mae: 4.9472\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1130 - mae: 7.1130\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 35.4567 - mae: 35.4567\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 34.8634 - mae: 34.8634\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9846 - mae: 7.9846\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.7004 - mae: 14.7004\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.7196 - mae: 16.7196\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9329 - mae: 15.9329\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1644 - mae: 16.1644\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.9324 - mae: 13.9324\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.0504 - mae: 18.0504\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.6120 - mae: 15.6120\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.2041 - mae: 21.2041\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.2732 - mae: 25.2732\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.3176 - mae: 16.3176\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2729 - mae: 7.2729\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.9688 - mae: 16.9688\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1225 - mae: 7.1225\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2058 - mae: 9.2058\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0961 - mae: 8.0961\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.0538 - mae: 17.0538\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.8627 - mae: 8.8627\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1711 - mae: 13.1711\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.7886 - mae: 8.7886\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.8161 - mae: 18.8161\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.0531 - mae: 14.0531\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.6831 - mae: 14.6831\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.8045 - mae: 15.8045\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.6810 - mae: 17.6810\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.2367 - mae: 13.2367\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.5070 - mae: 14.5070\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.2322 - mae: 23.2322\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3009 - mae: 9.3009\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 36.6569 - mae: 36.6569\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.8205 - mae: 21.8205\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2792 - mae: 7.2792\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.7127 - mae: 24.7127\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4220 - mae: 12.4220\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.5823 - mae: 10.5823\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 14.4883 - mae: 14.4883\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6132 - mae: 8.6132\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 43.0580 - mae: 43.0580\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.4611 - mae: 18.4611\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8820 - mae: 6.8820\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7211 - mae: 13.7211\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.0154 - mae: 21.0154\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.3731 - mae: 19.3731\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4735 - mae: 11.4735\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5302 - mae: 7.5302\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.6453 - mae: 21.6453\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 33.1785 - mae: 33.1785\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0833 - mae: 10.0833\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.1012 - mae: 12.1012\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.1372 - mae: 26.1372\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.1751 - mae: 12.1751\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3272 - mae: 13.3272\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 29.3775 - mae: 29.3775\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.3329 - mae: 7.3329\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 31.1362 - mae: 31.1362\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 12.3015 - mae: 12.3015\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4103 - mae: 16.4103\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.9118 - mae: 21.9118\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.1501 - mae: 22.1501\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7429 - mae: 7.7429\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1429 - mae: 8.1429\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.9435 - mae: 24.9435\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6958 - mae: 13.6958\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8926 - mae: 6.8926\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.5352 - mae: 24.5352\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.1721 - mae: 20.1721\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9658 - mae: 11.9658\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.5391 - mae: 16.5391\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.8017 - mae: 16.8017\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.2711 - mae: 15.2711\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 22.7179 - mae: 22.7179\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9234 - mae: 17.9234\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.9440 - mae: 10.9440\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.1530 - mae: 23.1530\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 17.7331 - mae: 17.7331\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9824 - mae: 6.9824\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.1857 - mae: 25.1857\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9025 - mae: 8.9025\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7668 - mae: 17.7668\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0002 - mae: 11.0002\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.9191 - mae: 12.9191\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.4033 - mae: 8.4033\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.6094 - mae: 13.6094\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4404 - mae: 7.4404\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.7099 - mae: 10.7099\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.2814 - mae: 13.2814\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.9763 - mae: 29.9763\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6304 - mae: 7.6304\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 9.9106 - mae: 9.9106\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.7669 - mae: 23.7669\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.3937 - mae: 16.3937\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.0758 - mae: 21.0758\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9367 - mae: 7.9367\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9731 - mae: 17.9731\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2375 - mae: 10.2375\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3338 - mae: 8.3338\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.0621 - mae: 5.0621\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5109 - mae: 23.5109\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.8309 - mae: 6.8309\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.3863 - mae: 16.3863\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.5019 - mae: 7.5019\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.0573 - mae: 20.0573\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7661 - mae: 13.7661\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.8282 - mae: 16.8282\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.0514 - mae: 7.0514\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.4846 - mae: 21.4846\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 12.2880 - mae: 12.2880\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.8117 - mae: 11.8117\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.3600 - mae: 8.3600\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4833 - mae: 12.4833\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 32.2171 - mae: 32.2171\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4477 - mae: 10.4477\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.6832 - mae: 19.6832\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 35.0762 - mae: 35.0762\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4192 - mae: 10.4192\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7625 - mae: 9.7625\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9500 - mae: 11.9500\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3943 - mae: 9.3943\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6071 - mae: 5.6071\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 37.4876 - mae: 37.4876\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.8830 - mae: 16.8830\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8748 - mae: 12.8748\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.1960 - mae: 8.1960\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.5568 - mae: 13.5568\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4354 - mae: 15.4354\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.9626 - mae: 32.9626\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.2040 - mae: 14.2040\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9196 - mae: 15.9196\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.0878 - mae: 19.0878\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.1178 - mae: 34.1178\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6798 - mae: 7.6798\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.2287 - mae: 25.2287\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.6759 - mae: 22.6759\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.8765 - mae: 8.8765\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.4709 - mae: 21.4709\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.6073 - mae: 20.6073\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0611 - mae: 7.0611\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.8117 - mae: 25.8117\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 32.2247 - mae: 32.2247\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0204 - mae: 10.0204\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.4171 - mae: 30.4171\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5020 - mae: 10.5020\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.9909 - mae: 14.9909\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 14.6580 - mae: 14.6580\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 23.3672 - mae: 23.3672\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1025 - mae: 13.1025\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2586 - mae: 9.2586\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6648 - mae: 9.6648\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0041 - mae: 13.0041\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.8863 - mae: 14.8863\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.7932 - mae: 14.7932\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.2751 - mae: 16.2751\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 20.8307 - mae: 20.8307\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 33.5317 - mae: 33.5317\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 8.2166 - mae: 8.2166\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.0960 - mae: 13.0960\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3999 - mae: 8.3999\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1283 - mae: 7.1283\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.9390 - mae: 10.9390\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.7654 - mae: 19.7654\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8625 - mae: 24.8625\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7422 - mae: 8.7422\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.9488 - mae: 5.9488\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 24.4400 - mae: 24.4400\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9771 - mae: 5.9771\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.3250 - mae: 16.3250\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0917 - mae: 6.0917\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0963 - mae: 11.0963\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.9601 - mae: 14.9601\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.6462 - mae: 7.6462\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7654 - mae: 8.7654\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 14.5991 - mae: 14.5991\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.3166 - mae: 11.3166\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.9080 - mae: 21.9080\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.8653 - mae: 14.8653\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4970 - mae: 8.4970\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.3957 - mae: 10.3957\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3392 - mae: 6.3392\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4602 - mae: 17.4602\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.4627 - mae: 11.4627\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.7294 - mae: 20.7294\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.3338 - mae: 31.3338\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2542 - mae: 9.2542\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.8621 - mae: 14.8621\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7182 - mae: 21.7182\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6615 - mae: 12.6615\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.0687 - mae: 6.0687\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.2201 - mae: 13.2201\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.4244 - mae: 27.4244\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6407 - mae: 10.6407\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8230 - mae: 12.8230\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.8836 - mae: 15.8836\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.7510 - mae: 24.7510\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.3753 - mae: 17.3753\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.8241 - mae: 7.8241\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.3789 - mae: 25.3789\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.1031 - mae: 15.1031\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1643 - mae: 7.1643\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.3318 - mae: 20.3318\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.3283 - mae: 6.3283\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.9961 - mae: 12.9961\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 10.7869 - mae: 10.7869\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.4007 - mae: 11.4007\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6152 - mae: 10.6152\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.4582 - mae: 11.4582\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.3851 - mae: 11.3851\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 30.3986 - mae: 30.3986\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.5052 - mae: 10.5052\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 28.8810 - mae: 28.8810\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 8.5916 - mae: 8.5916\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.7378 - mae: 12.7378\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.6754 - mae: 33.6754\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0963 - mae: 15.0963\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.4813 - mae: 17.4813\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.3049 - mae: 22.3049\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.5841 - mae: 23.5841\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 11.0008 - mae: 11.0008\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.9175 - mae: 14.9175\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.9979 - mae: 17.9979\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.4482 - mae: 5.4482\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0527 - mae: 10.0527\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.0052 - mae: 14.0052\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 16.7782 - mae: 16.7782\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 14.2937 - mae: 14.2937\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 30.6193 - mae: 30.6193\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.6541 - mae: 7.6541\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.1428 - mae: 28.1428\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.0017 - mae: 8.0017\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3933 - mae: 10.3933\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.0242 - mae: 15.0242\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 16.5653 - mae: 16.5653\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.8566 - mae: 26.8566\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4852 - mae: 12.4852\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4784 - mae: 12.4784\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.3186 - mae: 13.3186\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 29.5524 - mae: 29.5524\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4664 - mae: 3.4664\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.2136 - mae: 15.2136\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 20.8327 - mae: 20.8327\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 30.5108 - mae: 30.5108\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0597 - mae: 11.0597\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.8372 - mae: 12.8372\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.2398 - mae: 3.2398\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.6964 - mae: 16.6964\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3883 - mae: 13.3883\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 15.2771 - mae: 15.2771\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.7448 - mae: 11.7448\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4113 - mae: 16.4113\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.8785 - mae: 13.8785\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 30.6702 - mae: 30.6702\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.5880 - mae: 8.5880\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.7384 - mae: 10.7384\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 17.9051 - mae: 17.9051\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.8095 - mae: 15.8095\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.3054 - mae: 21.3054\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.3845 - mae: 25.3845\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.9815 - mae: 23.9815\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.7734 - mae: 5.7734\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.0010 - mae: 20.0010\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.0419 - mae: 14.0419\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.6088 - mae: 30.6088\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9409 - mae: 11.9409\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.7352 - mae: 12.7352\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.6139 - mae: 23.6139\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.5365 - mae: 20.5365\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.9942 - mae: 4.9942\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.7986 - mae: 12.7986\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 13.3772 - mae: 13.3772\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6727 - mae: 12.6727\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 17.6192 - mae: 17.6192\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 23.5629 - mae: 23.5629\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3755 - mae: 9.3755\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6316 - mae: 14.6316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92f971c290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "NBu2jLHeMJbt",
        "outputId": "26e673be-baf2-4365-9373-1d5b5edf23ff"
      },
      "source": [
        "#y_preds_1 = model_1.predict(X_test) #We're going to make predictions on the test data because our model has never seen the test data and we're interest in how our model will perform on data it's never seen before\n",
        "#plot_predictions(predictions=y_preds_1)\n",
        "\n",
        "\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_3)  #Review"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXhizQxgMzkX"
      },
      "source": [
        "#Our model did a horrible job here. This is an example of 'overfitting' or training to long\n",
        "#https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGhMbjZ1NLZh",
        "outputId": "f80804cd-fb15-4e83-fccf-5c1976411c86"
      },
      "source": [
        "# Calculate model_3 evaluation metrics\n",
        "mae_3 = mae(y_test, y_preds_2)\n",
        "mse_3 = mse(y_test, y_preds_2)\n",
        "mae_2, mse_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=59.02484>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=3536.0774>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOEDVYO_NjS-"
      },
      "source": [
        "#instead of having to scroll back and forth to compare our models let's put them here in a more structured manner\n",
        "#Comparing the results of our experiements\n",
        "#We've run a few experiments now, let's compare the results - which worked and which didn't"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "d5-7K7JbN6mF",
        "outputId": "55338c50-eb72-4840-98a3-1c1cf78f4850"
      },
      "source": [
        "#Let's compare our results by using a pandas df (which is just a table)\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [['model_1', mae_1.numpy(), mse_1.numpy()],   #try it without .numpy() and you'll see what it looks like\n",
        "                 ['model_2', mae_2.numpy(), mse_2.numpy()],   #much more readable with .numpy\n",
        "                 ['model_3', mae_3.numpy(), mse_3.numpy()]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=['models', 'mae', 'mse'])\n",
        "all_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>models</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>59.024841</td>\n",
              "      <td>3536.077393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>59.024841</td>\n",
              "      <td>3536.077393</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    models        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2  59.024841  3536.077393\n",
              "2  model_3  59.024841  3536.077393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqQ8I3uiP6vS",
        "outputId": "2922b772-2222-44a1-e5f0-6bddb21e9759"
      },
      "source": [
        "#It looks like model_2 performed the best\n",
        "#What was our model 2?\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZFr5FMQRfe"
      },
      "source": [
        "#One of your main goals should be to minimize the time between your experiements. The more experiments you do the more things you'll figure out which don't work and in turn, you'll get closer to figuring our what does work. 'Experiment', 'experiement', 'experiment. Start with small experiements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUYKjAMLvSQ3"
      },
      "source": [
        "#Model 2 is performing the best so far. How can we save it so that we can use it somewhere else?\n",
        "\n",
        "#There are two main formats we can save our model's too:\n",
        "#1. The SavedModel format is the default - allows you to resume training exactly where you left off.\n",
        "#2. the HDF5 format\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zF8qCYQwMs4",
        "outputId": "8f012165-f699-47c1-9e3c-ea8ad403d0c6"
      },
      "source": [
        "# Save model using the SavedModel format\n",
        "model_2.save('best_model_SavedModel_format')   #as a parameter 'just give it a name'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMqEasvjxYlO",
        "outputId": "0e7a45df-30de-4131-c9c2-562d37e45bfa"
      },
      "source": [
        "model_2.save('best_model_HDF5_format.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztaOQs6rx2Aj"
      },
      "source": [
        "#What's the easiest way to check if we saved our files correctly?\n",
        "#It's by loading them in"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13orvLwUyZ-g"
      },
      "source": [
        "Loading in a saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZlXBUPLyeKG",
        "outputId": "e54415f2-1e46-47ad-a3c7-168d8d0cbffb"
      },
      "source": [
        "# Load in a SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model('/content/best_model_SavedModel_format')   #click 'copy path' SavedModel folder in folders on left. Turn into a string\n",
        "loaded_SavedModel_format.summary()   #You can use something like .summary to make sure that it works"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdEaaZhMzf-B",
        "outputId": "aea4fefe-d8d9-4000-90ca-fa51794c4f56"
      },
      "source": [
        "#Compare model_2 predictions with SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "model_2_preds == loaded_SavedModel_format   #Check for equality"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy74lpg80C9u"
      },
      "source": [
        "#Why are they not the same? Why evaluating to false. Investigate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO3YdyBv0O7V",
        "outputId": "a995ff1a-2b2c-4f60-d4b5-80fc2908b64b"
      },
      "source": [
        "model_2_preds, loaded_SavedModel_format_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[22.288586],\n",
              "        [23.774488],\n",
              "        [25.260393],\n",
              "        [26.7463  ],\n",
              "        [28.232204],\n",
              "        [29.718111],\n",
              "        [31.204018],\n",
              "        [32.68992 ],\n",
              "        [34.175823],\n",
              "        [35.66173 ]], dtype=float32), array([[22.288586],\n",
              "        [23.774488],\n",
              "        [25.260393],\n",
              "        [26.7463  ],\n",
              "        [28.232204],\n",
              "        [29.718111],\n",
              "        [31.204018],\n",
              "        [32.68992 ],\n",
              "        [34.175823],\n",
              "        [35.66173 ]], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKZA_Ewv0lqI"
      },
      "source": [
        "#They look the same. We'll have to compare another way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiT439oB0pt_",
        "outputId": "888f9917-b7f5-46dc-f3d1-5529d5a239a3"
      },
      "source": [
        "mae(y_true=y_test, y_pred=model_2_preds) == mae(y_true=y_test, y_pred=loaded_SavedModel_format_preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsuWrvju1KT1"
      },
      "source": [
        "#evaluate to True. They have the same error.\n",
        "#Maybe they evaluated to false above because of how the computer stores numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfvADNyo1YyK",
        "outputId": "333ed19d-bcd7-4479-eaca-94e2044c1fa0"
      },
      "source": [
        "model_2_preds.squeeze() == loaded_SavedModel_format_preds.squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSZXf4S41ex9",
        "outputId": "2387af12-c448-4e9d-f47d-19e8736bd34f"
      },
      "source": [
        "loaded_SavedModel_format_preds.squeeze()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([22.288586, 23.774488, 25.260393, 26.7463  , 28.232204, 29.718111,\n",
              "       31.204018, 32.68992 , 34.175823, 35.66173 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbqGLiOS122o"
      },
      "source": [
        "#The error occured b/c of a simple typo. \n",
        "#We should have typed:\n",
        "# model_2_preds == loaded_SavedModel_format_preds\n",
        "#We forgot the second preds!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ONUv_Z2SWm",
        "outputId": "93b1cdc9-c0c7-4944-f33c-e4658d1b0c82"
      },
      "source": [
        "loaded_h5_model = tf.keras.models.load_model('/content/best_model_HDF5_format.h5')\n",
        "loaded_h5_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f92fdc8b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taq3pgsa3DMP",
        "outputId": "fc3e644f-f1f3-4e09-9486-e1d2ede486b5"
      },
      "source": [
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "\n",
        "model_2_preds == loaded_h5_model_preds\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzLGmZuG4QxP"
      },
      "source": [
        "#How might we download a model (or any other file) from Google Colab\n",
        "\n",
        "#If you want to download your files from Google Colab:\n",
        "\n",
        "#1. You can go to the 'files' tab and right click on the file you're after and click 'download'\n",
        "\n",
        "#2. Use code (see the cell below).\n",
        "\n",
        "#3. Save it to Google Drive by connecting Google Drive and copying it there."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "EBBvB6vK5Crt",
        "outputId": "14ab836f-2f48-4015-edf8-df77d11fd874"
      },
      "source": [
        "#Download a file from Google Colab\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/best_model_HDF5_format.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_21c28362-e9d6-49d6-88ea-4240fa218ae3\", \"best_model_HDF5_format.h5\", 14488)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8JLPxAn598M"
      },
      "source": [
        "#Save a file from Google Colab to Google Drives (requires mounting Google Drive)\n",
        "#!cp /content/best_model_HDF5_format.h5 /content/tensorflow_course... #!cp = copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6f7bEEUeeSY"
      },
      "source": [
        "# !ls /content/drive/MyDrive/tensorflow_course"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3iznK59erVw"
      },
      "source": [
        "A larger example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cWWyyzRetAc",
        "outputId": "52efc4cd-a9ff-4332-b4c1-dada4e88e8b5"
      },
      "source": [
        "X_train, y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56], dtype=int32)>,\n",
              " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1HrAgC6fk03"
      },
      "source": [
        "#Import the required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "WrekrBxGf0ZM",
        "outputId": "f96dc56a-7a90-4d2b-80af-6ea3d20af4e2"
      },
      "source": [
        "# Read in the insurance dataset\n",
        "\n",
        "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBuP9BeBgU9R"
      },
      "source": [
        "#What is our dependent variable?    Our dependent variable is our charges - that's what we're trying to predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn7vzw87gf51"
      },
      "source": [
        "#What are our independent variables (aka features) - sex, age, region, smoker, bmi..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRAkwb8ig9eH"
      },
      "source": [
        "#some of our features are objects (such as sex/male/female, region, etc) - we want to turn these into numbers - numerical encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqqY7P-RhOZM"
      },
      "source": [
        "#How can we do this?\n",
        "#Let's use 'one hot encoding' to turn male/female into numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM-xfJsvhvfu"
      },
      "source": [
        "#Google how to one hot encode a pandas dataframe - it recommends 'get dummies'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B0g3po14h1In",
        "outputId": "d489a791-2e6b-411e-ad2a-ddbef1d2c9a0"
      },
      "source": [
        "insurance_one_hot = pd.get_dummies(insurance)   #on line 99 we called our df insurance\n",
        "# we save pd.get_dummies(insurance) to the variable insurance_one_hot\n",
        "insurance_one_hot.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvtqe0723Opo"
      },
      "source": [
        "# Create X and y values (features and labels)\n",
        "X = insurance_one_hot.drop('charges', axis=1)  #what are our features? Basically every column except for our features\n",
        "#What is axis=1 stand for???\n",
        "y = insurance_one_hot['charges']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Fyo6qmP73-7-",
        "outputId": "684bb5b8-ad7c-45bd-c7d0-7ad286a5470f"
      },
      "source": [
        "# View X\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enKv-qM44Lvd",
        "outputId": "fab43d7b-8cba-475b-e312-672978aca9d6"
      },
      "source": [
        "# View y\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Kt96bS4VXr"
      },
      "source": [
        "#Right now X and y are in pandas data frames. Our neural network will automatically convert them into formats capable of being used in our neural networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj7CcbMM4rBk"
      },
      "source": [
        "#Create training and test sets\n",
        "#X[:40]  previously we did it like this\n",
        "\n",
        "#This time we're going to use a very popular function to do it\n",
        "from sklearn.model_selection import train_test_split    #This is very popular and useful\n",
        "#It splits arrays or matrices into random train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   #This comes directly from here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFwfGEFS6BuM",
        "outputId": "19358c88-d133-47a0-92cf-ec9c06b3eccf"
      },
      "source": [
        "len(X), len(X_train), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_K8AitO6TE1",
        "outputId": "839bcfbc-bc54-4c80-d89e-b302911c0355"
      },
      "source": [
        "#Our test dataset has 20% of the sample\n",
        "0.2*1338"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "267.6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxWSORtM6g7B"
      },
      "source": [
        "#2. Build a neural network that will take in X_train and y_train and learn the relationships between the 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wa6rCTM6x6D",
        "outputId": "b65797ab-3298-48f9-cf95-74e518614066"
      },
      "source": [
        "#It's sort of like model_2 above\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 10)                20        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N91ErDKt691s",
        "outputId": "c4d8d5f8-5421-4761-9dc4-0ec97797ea08"
      },
      "source": [
        "#Just like model 2 above\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create a model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(10),                     \n",
        "                  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "insurance_model.compile(loss='mae', optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=['mae']\n",
        "                        )\n",
        "\n",
        "#3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7886.7759 - mae: 7886.7759\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7558.1470 - mae: 7558.1470\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7792.0220 - mae: 7792.0220\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.3887 - mae: 7748.3887\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.3940 - mae: 7595.3940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7589.9844 - mae: 7589.9844\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7698.5576 - mae: 7698.5576\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.7778 - mae: 7496.7778\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7493.1743 - mae: 7493.1743\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7769.7295 - mae: 7769.7295\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7706.9028 - mae: 7706.9028\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7687.7231 - mae: 7687.7231\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.9004 - mae: 7689.9004\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.5327 - mae: 7393.5327\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.6987 - mae: 7780.6987\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.5098 - mae: 7578.5098\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7750.8354 - mae: 7750.8354\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7739.2144 - mae: 7739.2144\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7875.0654 - mae: 7875.0654\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7466.6768 - mae: 7466.6768\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7941.2329 - mae: 7941.2329\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7640.2725 - mae: 7640.2725\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7539.2671 - mae: 7539.2671\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7619.9653 - mae: 7619.9653\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.1719 - mae: 7644.1719\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7709.0371 - mae: 7709.0371\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7366.8662 - mae: 7366.8662\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7444.3154 - mae: 7444.3154\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.4077 - mae: 7616.4077\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7686.3853 - mae: 7686.3853\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.0977 - mae: 7548.0977\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7501.5532 - mae: 7501.5532\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7363.4160 - mae: 7363.4160\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7295.4478 - mae: 7295.4478\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.8813 - mae: 7569.8813\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.1997 - mae: 7548.1997\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7424.3975 - mae: 7424.3975\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7529.7734 - mae: 7529.7734\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.3232 - mae: 7467.3232\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7635.9292 - mae: 7635.9292\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7536.8398 - mae: 7536.8398\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.5859 - mae: 7616.5859\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7439.4941 - mae: 7439.4941\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7538.0151 - mae: 7538.0151\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7415.1470 - mae: 7415.1470\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7420.6938 - mae: 7420.6938\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7509.9839 - mae: 7509.9839\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7541.1133 - mae: 7541.1133\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7467.8643 - mae: 7467.8643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7389.3560 - mae: 7389.3560\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7499.7749 - mae: 7499.7749\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.9282 - mae: 7523.9282\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7243.3115 - mae: 7243.3115\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7429.5864 - mae: 7429.5864\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.3999 - mae: 7313.3999\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7526.3877 - mae: 7526.3877\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7542.2666 - mae: 7542.2666\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7576.9277 - mae: 7576.9277\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7546.4048 - mae: 7546.4048\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7351.2261 - mae: 7351.2261\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7302.1436 - mae: 7302.1436\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.0879 - mae: 7393.0879\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.2881 - mae: 7442.2881\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7492.6782 - mae: 7492.6782\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7561.9165 - mae: 7561.9165\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7340.5137 - mae: 7340.5137\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.0845 - mae: 7496.0845\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7617.0303 - mae: 7617.0303\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7641.1948 - mae: 7641.1948\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.2744 - mae: 7084.2744\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7240.4902 - mae: 7240.4902\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7283.4888 - mae: 7283.4888\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.5083 - mae: 7335.5083\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.6392 - mae: 7275.6392\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.1860 - mae: 7313.1860\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7485.7588 - mae: 7485.7588\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7352.2803 - mae: 7352.2803\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7520.5703 - mae: 7520.5703\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7279.3779 - mae: 7279.3779\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7273.8477 - mae: 7273.8477\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7176.5215 - mae: 7176.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7425.6289 - mae: 7425.6289\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.1294 - mae: 7403.1294\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.7271 - mae: 7484.7271\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7217.6074 - mae: 7217.6074\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7134.1562 - mae: 7134.1562\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7083.4360 - mae: 7083.4360\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7254.1782 - mae: 7254.1782\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7268.7456 - mae: 7268.7456\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7470.5220 - mae: 7470.5220\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7210.9536 - mae: 7210.9536\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7395.6816 - mae: 7395.6816\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7328.0884 - mae: 7328.0884\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7230.4380 - mae: 7230.4380\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.3936 - mae: 7261.3936\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7342.5684 - mae: 7342.5684\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7106.1714 - mae: 7106.1714\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fd0ae290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI45IKnE84u1",
        "outputId": "c49c0f4d-d729-41b7-8c13-21a052813e10"
      },
      "source": [
        "# Check the results of the insurance model on the test data\n",
        "\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 1ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52PvuLv9Hmn"
      },
      "source": [
        "#We can see in the cell above that it's performing even better on the test dataset than the training dataset. Training loss = 7106. Test loss = 7023"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdQwvx2Y9YBe",
        "outputId": "48320706-34b7-465d-adc5-746814a74d7c"
      },
      "source": [
        "#mae is tell us that on average our model is wrong by about 7,000. \n",
        "#Is that number large?\n",
        "#Take a look at y_train to compare\n",
        "y_train.median(), y_train.mean()   #This shows (in the cell below, that our model is substantially wrong b/c the average insurance cost is 13,346 and our model is off by > 7,000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364489)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKACO4ww-Vvo"
      },
      "source": [
        "#Right now our model isn't performing well. Let's try to improve it!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVK_dydV-f3g"
      },
      "source": [
        "#insurance_model_2\n",
        "\n",
        "#tf.random.set_seed(42)\n",
        "\n",
        "#Create model_2\n",
        "\n",
        "#insurance_model_2 = tf.keras.Sequential(\n",
        "#    [\n",
        "#        tf.keras.layers.Dense(1),\n",
        "#        tf.keras.layers.Dense(10),\n",
        "#        tf.keras.layers.Dense(2),\n",
        "#    ]\n",
        "#)\n",
        "#2. Compile the model\n",
        "#insurance_model_2.compile(loss='mae',\n",
        "#                          optimizer=tf.keras.optimizers.Adam(),\n",
        "#                          metrics=['mae']\n",
        "#                          )\n",
        "\n",
        "#3. Fit the model\n",
        "#insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l-axlJeBCzs"
      },
      "source": [
        "#insurance_model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LnFHUybQRsX"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "#https://keras.io/api/callbacks/early_stopping/\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Add an extra layer and increase number of units\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100), # 100 units\n",
        "  tf.keras.layers.Dense(10), # 10 units\n",
        "  tf.keras.layers.Dense(1) # 1 unit (important for output layer)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(), # Adam works but SGD doesn't \n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model and save the history (we can plot this)\n",
        "history = insurance_model_2.fit(X_train, y_train, epochs=100, callbacks=[callback], verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT4uGaKnQjAV",
        "outputId": "8c7a7404-0bf4-402b-c0b6-cae528dccc66"
      },
      "source": [
        "# Evaluate our larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXve2Gv1QmM-"
      },
      "source": [
        "#Much better! Using a larger model and the Adam optimizer results in almost half the error as the previous model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Fzjp9zcMQudd",
        "outputId": "86fa5090-9b96-4d27-b218-500a42936dff"
      },
      "source": [
        "\n",
        "# Plot history (also known as a loss curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGKZ_RnWRW4i"
      },
      "source": [
        "#the loss is still decreasing - but not as dramatically"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoY4fJThRfp2"
      },
      "source": [
        "#How long should you train for?\n",
        "#It depends - it depends on the problem you're working on.\n",
        "###Tensorflow has a solution! It's call the [EarlyStopping Callback], which is a TensorFlow component you can add to your model to stop training once it stops improving a certain amount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T76XXUGTftK"
      },
      "source": [
        "#Preprocessing (normalization and standardization) - what can we do to improve the preprocessing of our data?\n",
        "#Let's go back to step #1 - getting our data ready (to make it better)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seSKb6AEUFar"
      },
      "source": [
        "#What is Normalization?\n",
        "#Normalization in machine learning is part of data preparation for ML.\n",
        "#The goal of normalization is to change the values of numeric colums in the dataset to a common scale, without distoring difference in the ranges of values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4dgq3rMaUhHV",
        "outputId": "14344f0c-8f3b-4c79-b20a-81d1bf678fab"
      },
      "source": [
        "X.head()   #we can see that age and BMI are on different scales"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1Ea8xgiCUues",
        "outputId": "3d3f6895-4456-4580-b47e-e50792b4d0f0"
      },
      "source": [
        "X['age'].plot(kind='hist')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92fe860410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "I_NcT8JmU20Y",
        "outputId": "da4a8c14-3490-4901-c749-a4bcb0b9a86f"
      },
      "source": [
        "X['bmi'].plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f92fe80a990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dIDu0aLU-R3"
      },
      "source": [
        "#We can see that age goes from 20-60   and 'bmi' goes from 15-50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh58a9JGVLUX",
        "outputId": "1382a310-a44b-4c97-aefb-3dfe92d807ef"
      },
      "source": [
        "X['children'].value_counts()   #a lot of people with 0 children. 18 people with 5 children\n",
        "#So this histogram would only go from 0-5.\n",
        "###What if we wanted to get all of them between 0-1?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    574\n",
              "1    324\n",
              "2    240\n",
              "3    157\n",
              "4     25\n",
              "5     18\n",
              "Name: children, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_wzuJZMVvFE"
      },
      "source": [
        "#We can Normalize our data with Scikit-Learn's MinMaxScaler - converts all values to btwn 0-1 whilst preserving the original distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLzRKumEWIYF"
      },
      "source": [
        "#In terms of scaling values, neural networks tend to prefer normalization."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "jxaVEP27WaXE",
        "outputId": "0541b48d-a0ca-4e64-dfb4-6601e442a5fc"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "#Read in the insurance df\n",
        "insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n",
        "insurance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOuQXtq4W97h"
      },
      "source": [
        "#To prepare our data, we can borrow a few classes from Scikit-Learn\n",
        "\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), ['age', 'bmi', 'children']), #turn all values in these columns btwn 0 and 1. How did we know to do this? B/c age, bmi, children are the numberical columns. We don't need to scale our target variable ('charges')\n",
        "     (OneHotEncoder(handle_unknown='ignore'), ['sex', 'smoker', 'region']))                                     \n",
        "                        \n",
        "#for the nonnumerical columns (sex, smoker, region) we know that we will one hot encode these           \n",
        "#handle_unknown='ignore' means that if there's any column that OneHotEncoder doesn't know about...just ignore them\n",
        "#as we pass our data through the above it's going to get MixMaxScaled on age, bmi, and children and OneHotEncoded on sex, smoker and region\n",
        "\n",
        "#Create X and y - turn our data into features and labels\n",
        "X = insurance.drop('charges', axis=1)\n",
        "y = insurance['charges']   #The thing that we're trying to predict goes on the y axis\n",
        "\n",
        "# Build our train and test sets - we split our data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Fit the column transformer to our training data...don't fit it to our test data because our test data is from the future\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler and OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)  #We've normalized our data and one hot encoded it\n",
        "X_test_normal = ct.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIGvEOT_ty7S",
        "outputId": "6bf23278-cc10-4fa9-815a-124dbbb6b824"
      },
      "source": [
        "#What does our data look like now?\n",
        "X_train.loc[0]   #Interesting .loc[0] looks at the first person"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYc_nE0luGMP",
        "outputId": "f8f28c99-6f31-4aea-bcaa-0a60f3133f1b"
      },
      "source": [
        "#We actually want to look at \n",
        "X_train_normal[0]\n",
        "\n",
        "#In the above cell - that's what we started with\n",
        "\n",
        "#In the below cell - that's what we have after MinMaxScaler! 0.608 must be the age, 0.107 is the sex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-j385W-u2Dw",
        "outputId": "aba06ad1-838b-4f7b-eb75-f8c4e8ccba70"
      },
      "source": [
        "#Let's take a look at the whole thing\n",
        "\n",
        "X_train_normal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8AAmAkku7L1"
      },
      "source": [
        "#It's all in numerical format. Incredible!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1WkrbLZvHsp",
        "outputId": "e6bb5369-361d-4252-f7a8-86095e62d11f"
      },
      "source": [
        "#Let's look at the shape:\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuDI3urWvNvB"
      },
      "source": [
        "#Normalizing it and OneHotEncoding it added some extra columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdqS5NqRvWRG"
      },
      "source": [
        "Beautiful! I normalized and one hot encoded our data. Now I'll build a neural network model on it and see how it goes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZNHxYwovy2o",
        "outputId": "ca8e06c3-584c-4f66-e067-f760bdadb564"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "#Create model\n",
        "\n",
        "#These numbers below are based on our insurance_model_2 model b/c it was our best performing\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(100),\n",
        "        tf.keras.layers.Dense(10),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss='mae',\n",
        "              optimizer=tf.keras.optimizers.Adam(),   #Keep in mind that your learning rate (lr) is potentially the most important hyperparameter that you can change\n",
        "              metrics = ['mae'])\n",
        "\n",
        "#here's the difference from our previous models - next line we're doing it on normalized data\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=100 )"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13342.6475 - mae: 13342.6475\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13333.4785 - mae: 13333.4785\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13312.0234 - mae: 13312.0234\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13267.7930 - mae: 13267.7930\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13189.5850 - mae: 13189.5850\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 13066.4502 - mae: 13066.4502\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12888.1953 - mae: 12888.1953\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12644.6523 - mae: 12644.6523\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12325.5469 - mae: 12325.5469\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11925.9658 - mae: 11925.9658\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 11454.3350 - mae: 11454.3350\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10949.8086 - mae: 10949.8086\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9951.6250 - mae: 9951.6250\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9482.7422 - mae: 9482.7422\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 9066.7461 - mae: 9066.7461\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8721.9854 - mae: 8721.9854\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8441.2002 - mae: 8441.2002\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8227.5117 - mae: 8227.5117\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8081.9775 - mae: 8081.9775\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7973.8945 - mae: 7973.8945\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7899.1597 - mae: 7899.1597\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7840.3916 - mae: 7840.3916\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7787.9619 - mae: 7787.9619\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7749.2622 - mae: 7749.2622\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7697.9595 - mae: 7697.9595\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7656.0273 - mae: 7656.0273\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7613.4780 - mae: 7613.4780\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7570.9482 - mae: 7570.9482\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7527.4175 - mae: 7527.4175\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7483.5947 - mae: 7483.5947\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7439.4424 - mae: 7439.4424\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7395.0552 - mae: 7395.0552\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7346.8125 - mae: 7346.8125\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7300.0493 - mae: 7300.0493\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7249.8452 - mae: 7249.8452\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7199.5303 - mae: 7199.5303\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7148.4805 - mae: 7148.4805\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7093.6660 - mae: 7093.6660\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7038.1797 - mae: 7038.1797\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6981.7393 - mae: 6981.7393\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6922.7847 - mae: 6922.7847\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6860.1724 - mae: 6860.1724\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6793.7979 - mae: 6793.7979\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6726.6201 - mae: 6726.6201\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6657.4683 - mae: 6657.4683\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6586.3086 - mae: 6586.3086\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6507.5063 - mae: 6507.5063\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.6025 - mae: 6428.6025\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6342.7100 - mae: 6342.7100\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6258.0718 - mae: 6258.0718\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6164.7046 - mae: 6164.7046\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6068.6748 - mae: 6068.6748\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5970.0981 - mae: 5970.0981\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5862.5625 - mae: 5862.5625\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5753.9531 - mae: 5753.9531\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5638.0942 - mae: 5638.0942\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5519.8687 - mae: 5519.8687\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5401.3198 - mae: 5401.3198\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5277.3506 - mae: 5277.3506\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5149.7642 - mae: 5149.7642\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5019.3540 - mae: 5019.3540\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4889.6865 - mae: 4889.6865\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4629.4370 - mae: 4629.4370\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4503.5991 - mae: 4503.5991\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4392.9922 - mae: 4392.9922\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4284.3862 - mae: 4284.3862\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4182.6182 - mae: 4182.6182\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4089.5720 - mae: 4089.5720\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4003.3901 - mae: 4003.3901\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3929.0093 - mae: 3929.0093\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3813.7144 - mae: 3813.7144\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3773.0317 - mae: 3773.0317\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3744.1995 - mae: 3744.1995\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3719.6870 - mae: 3719.6870\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3702.9109 - mae: 3702.9109\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3691.8792 - mae: 3691.8792\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.8350 - mae: 3682.8350\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3676.9763 - mae: 3676.9763\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3673.9492 - mae: 3673.9492\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3667.8452 - mae: 3667.8452\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3664.5757 - mae: 3664.5757\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3661.8562 - mae: 3661.8562\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.3049 - mae: 3660.3049\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3657.5134 - mae: 3657.5134\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.2200 - mae: 3655.2200\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3653.8831 - mae: 3653.8831\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3652.0195 - mae: 3652.0195\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3648.9990 - mae: 3648.9990\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3648.4463 - mae: 3648.4463\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3646.2297 - mae: 3646.2297\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3644.4377 - mae: 3644.4377\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3645.8772 - mae: 3645.8772\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3642.2573 - mae: 3642.2573\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.1184 - mae: 3640.1184\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.0649 - mae: 3638.0649\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.2051 - mae: 3637.2051\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3636.1707 - mae: 3636.1707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fe67e110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnnEGke05FFh",
        "outputId": "a7a0df49-94f2-4f14-ac7b-fc9b604e4d85"
      },
      "source": [
        "#Evaluate our insurance model trained on normalized data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test) #We have to evaluate it on the same type of data that it was trained on - so X_test_normal evaluate it on normalized data"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf78htnk6P1i"
      },
      "source": [
        "#compare it to our best model - insurance_model_2.evaluate...\n",
        "#We improved from about 5,000 mae to 3,438 mae just by normalizing our data"
      ],
      "execution_count": 151,
      "outputs": []
    }
  ]
}